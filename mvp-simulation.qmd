Below is a compact “starter-notebook” that mirrors the exact structure of Wager & Xu (2021).  
Every component is annotated so you can extend or swap in richer primitives without breaking the theory.

---

## 0.  Imports & global settings
```{python}
import numpy as np
from sklearn.linear_model import LinearRegression
from scipy.stats import lognorm
```

---

## 1.  Model primitives  (matches Section 3 of the paper)

### 1.1  Demand  
We draw a **total demand** \(D_t\) that is *exogenous* (payment-independent).

```{python}
# Context distribution  A_t  ~ LogNormal(μ, σ)
MU_A  = 4.5          # log-mean of demand shock
SIG_A = 0.22         # log-sd   "
def draw_demand():
    A = lognorm(s=SIG_A, scale=np.exp(MU_A)).rvs()  # demand shock
    return A            # This is total demand D_t for the day
```

### 1.2  Suppliers  
Each supplier i has a *fixed* break-even cost \(B_i\).

```{python}
N_SUP = 100                   # market size  (large ⇒ mean-field)
B_MIN, B_MAX = 20, 80            # support of break-even costs
B = np.random.uniform(B_MIN, B_MAX, N_SUP)    # vector of B_i
```

### 1.3  Allocation rule  ω  
Active suppliers share demand:  
\[
ω(x)=1-\exp(-x), \quad x=\tfrac{D}{T}.
\]

```{python}
def omega(d_over_t):
    """Expected demand served by one active supplier."""
    return 1 - np.exp(-d_over_t)

def omega_prime(d_over_t):
    """Derivative ω'(·) needed for Γ estimate."""
    return np.exp(-d_over_t)
```

### 1.4  Platform revenue  r  
Paper assumption:  \(R(D,T) ≈ r(D/T)\,T\).  
Take \(r(x)=p_{sale}\,ω(x)\) with \(p_{sale}=100 $/unit\).

```{python}
P_SALE = 100.0                       # value per unit demand filled
def r(d_over_t):
    return P_SALE * omega(d_over_t)

def r_prime(d_over_t):
    return P_SALE * omega_prime(d_over_t)
```

---

## 2.  One-day simulation given baseline payment \(p_t\)

```{python}
def simulate_day(p_base, zeta):
    """
    Returns: dict with (eps, Z, D, T, omega_val, revenue, payments, utility)
    """
    # 1) Local randomization  (Eq. 2.1 / 3.11)
    eps = np.random.choice([-1, 1], size=N_SUP)
    P_i = p_base + zeta * eps               # realised payments
    
    # 2) Exogenous demand
    D = draw_demand()
    
    # 3) Anticipated allocation if active  (depends on D and ex-post T, so iterate)
    #    Use mean-field fixed point: supplier joins if  P_i * ω(D/T) > B_i
    #    Solve via simple bisection on T
    def active_count(T_guess):
        alloc = omega(D / T_guess)          # allocation at this T
        return np.sum(P_i * alloc > B)      # implied active suppliers

    # Start at full market and contract until fixed point
    T = N_SUP
    while True:
        new_T = active_count(T)
        if new_T == T: break
        T = new_T if new_T > 0 else 1       # avoid divide-by-zero
    
    alloc = omega(D / T)
    Z = (P_i * alloc > B).astype(int)
    
    # 4) Utilities
    payments = np.sum(P_i * Z * alloc)
    revenue  = r(D / T) * T
    utility  = revenue - payments
    
    return dict(eps=eps, Z=Z, D=D, T=T, alloc=alloc,
                revenue=revenue, payments=payments, utility=utility,
                p_base=p_base)
```

---

## 3.  Estimating the marginal response Δ  (Lemma 4 / Eq. 3.17)

```{python}
def estimate_delta(batch_results):
    """
    OLS of Z_it on ε_it over the whole batch.
    Returns Δ_hat  (slope)  and  μ_hat (mean participation prob).
    """
    X, Y = [], []
    for res in batch_results:
        X.append(res["eps"])
        Y.append(res["Z"])
    X = np.concatenate(X).reshape(-1, 1)
    Y = np.concatenate(Y)
    
    model = LinearRegression().fit(X, Y)
    delta_hat = model.coef_[0]
    mu_hat    = model.intercept_
    return delta_hat, mu_hat
```

---

## 4.  Estimate **Γ**, the utility gradient  (Theorem 6)

For a single day result `res` with fixed point \(D,T\):

\[
\widehat{Υ}
  = \frac{\widehat{Δ}}
         {1 + (D/T)\,\widehat{Δ}\,\omega'(D/T)} ,
\qquad
\widehat{Γ}
  = \widehat{Υ}\,\Big[ r'(D/T) - ω'(D/T)\,p\Big]\,\frac{D}{T}
      - ω(D/T)\,p .      \tag{∗}
\]

```{python}
def estimate_gamma(batch_results, delta_hat, p_base):
    """Implements Eq.(*) above averaged across the batch."""
    numer, denom = 0.0, 0.0
    for res in batch_results:
        D, T   = res["D"], res["T"]
        z_bar  = np.mean(res["Z"])          # empirical μ
        x      = D / T
        w, w1  = omega(x), omega_prime(x)
        
        ups_hat = delta_hat / (1 + x * delta_hat * w1)
        gamma   = (ups_hat * (r_prime(x) - w1 * p_base) * x
                   - w * p_base)
        numer += gamma
        denom += 1
    return numer / denom
```

---

## 5.  Learning loop  (mirror-descent update 4.5)

```{python}
def learn_payments(T_total=400,
                   batch_size=40,
                   p_init=30.0,
                   zeta=1.0,
                   step_eta=1.0,
                   p_min=5.0, p_max=60.0):
    
    history = dict(p=[], util=[], grad=[])
    p_t = p_init
    θ_t = 0.0          # cumulative weighted gradients  θ_t   in (4.5)
    s_t = 0.0          # cumulative weights            Σ k   (here k=batch index)
    
    n_batches = T_total // batch_size
    for k in range(1, n_batches + 1):
        # --- collect data under payment p_t ---
        batch = []
        for day in range(batch_size):
            batch.append(simulate_day(p_t, zeta))
            print(f'Simulated day {(day + 1) + ((k - 1) * batch_size)}')
        
        # --- estimate gradient ---
        Δ_hat, _ = estimate_delta(batch)
        Γ_hat    = estimate_gamma(batch, Δ_hat, p_t)
        
        # --- mirror-descent update (simple Euclidean projection) ---
        θ_t += k * Γ_hat
        s_t += k
        p_t = np.clip(θ_t * step_eta / s_t, p_min, p_max)
        
        # --- logging ---
        history["p"].append(p_t)
        history["grad"].append(Γ_hat)
        history["util"].append(np.mean([b["utility"] for b in batch]))
        
        print(f"Batch {k:02d}:  Γ̂={Γ_hat:+.3f},  p_next={p_t:.2f},  Ū={history['util'][-1]:.1f}")
    
    return history
```

---

## 6.  Demo run

```{python}
np.random.seed(0)
hist = learn_payments(T_total=400, batch_size=40,
                      p_init=30, zeta=1, step_eta=1.0)
print(hist)
```

---

### What changed relative to the original notebook?

1. **No market-clearing price curve** – payments are posted, demand is exogenous.  
2. **Allocation rule ω(D/T)** and its derivative explicitly coded.  
3. **Supplier activation** uses expected revenue \(P_i ω\) versus private cost \(B_i\).  
4. **Local perturbations** implemented exactly as \(p_t ± ζ\).  
5. **Gradient estimator Γ̂** follows Theorem 6 verbatim.  
6. **Learning update** implements mirror descent (Eq. 4.5) with linear weights.  

The notebook is now fully aligned with **Wager & Xu (2021)** and can be expanded (different ω, richer cost distributions, larger zeta schedules, etc.) without violating the theoretical guarantees.